# å›¾åƒä¿®å¤ä¸å¯¹æ¯”å­¦ä¹ ï¼šä»å»é›¨ä»»åŠ¡å¼€å§‹

# Part1 å…ˆäº†è§£ä¸€äº›åŸºç¡€å†…å®¹

## Task1-æ— é›¨ = æœ‰é›¨ - é›¨å±‚ ï¼Ÿ

### åŸºç¡€é—®é¢˜ï¼š

**å­¦ä¼šä»æœ‰é›¨å›¾åƒåˆ°æ— é›¨å›¾åƒçš„ç«¯åˆ°ç«¯æ˜ å°„**ï¼š

è¿™ä¸ªæ–¹æ³•çœ‹ä¼¼æ¯”è¾ƒç›´æ¥ï¼Œä½†è¿™æ ·ä¼šæœ‰å‡ ä¸ªé—®é¢˜ï¼›ä¸€æ˜¯ç”±äºæ¨¡å‹å­¦ä¹ çš„æ˜¯æ•´ä¸ªç”»é¢ï¼ŒåŒæ—¶éœ€è¦æ¨¡å‹è®°ä½æ‰€æœ‰æ¨¡å‹çš„å†…å®¹ï¼Œè¿™æ ·æ—¢ä¼šä½¿å¾—æ¨¡å‹çš„è®­ç»ƒéš¾åº¦è¾ƒå¤§ï¼ŒåŒæ—¶è¾ƒéš¾æ”¶æ•›ï¼ŒåŒæ—¶ç”±äºæˆ‘ä»¬æ˜¯ç›´æ¥è®­ç»ƒå¾—åˆ°ç»“æœï¼Œåœ¨æ²¡é›¨çš„åœ°æ–¹å†…å®¹ä¹Ÿå¯èƒ½ä¼šå‘ç”Ÿæ”¹å˜ï¼ŒåŒæ—¶å¯èƒ½ä¼šå¸¦æ¥å¾ˆå¤šçš„å™ªç‚¹ã€‚

**æ®‹å·®å­¦ä¹ **ï¼š

æ®‹å·®å­¦ä¹ ç›¸å¯¹è€Œè¨€åªéœ€è¦æˆ‘ä»¬å…³æ³¨æ˜¯å¦å­˜åœ¨é›¨æ»´å³å¯ï¼Œè¿™ä½¿å¾—æ¨¡å‹ç›¸å¯¹è€Œè¨€æ›´åŠ ç®€å•ï¼ŒåŒæ—¶ä¹Ÿæ›´å®¹æ˜“æ”¶æ•›ã€‚è¿™æ ·æˆ‘ä»¬åªéœ€è¦å‡å»è¿™å±‚é›¨å±‚ï¼Œå¯¹å…¶ä»–åœ°æ–¹å›¾åƒçš„ç ´åå°±ä¼šè¾ƒå°ã€‚åŒæ—¶å­¦ä¹ é›¨æ»´çš„æ ·å­è€Œéåœºæ™¯ä¹Ÿä¼šå¸¦æ¥æ›´å¤šçš„æ³›åŒ–èƒ½åŠ›ï¼Œä½¿å¾—æ¨¡å‹æ›´å®¹æ˜“æ¨å¹¿åˆ°æ›´å¤šçš„åœºæ™¯ã€‚

**å›¾åƒï¼š**

![288985ad220041dd69bb5a0b3a27be08](./Img/288985ad220041dd69bb5a0b3a27be08.jpg)

### **é™„åŠ é—®é¢˜**ï¼š

#### 1.é›¨ä¸è¿™ä¸€ç‰©ä½“ï¼Œåœ¨å¤–è¡¨ä¸Šè¡¨ç°å‡ºçš„çº¿æ€§ç‰¹å¾ï¼Œå…¶å®ä¹Ÿå­˜åœ¨äºå…¶ä»–ç‰©ä½“ä¸­ï¼ˆå¦‚æ¡çº¹ã€çº¹ç†ç­‰ï¼‰ã€‚åœ¨é¢å¯¹è¿™ç§æƒ…å†µæ—¶ï¼Œ**æ¨¡å‹å¦‚ä½•åˆ†è¾¨è°æ˜¯é›¨ä¸ï¼Ÿ**

å…¶å®è¿™æ˜¯å¯ä»¥åŒºåˆ†çš„ï¼Œå°±åƒæˆ‘ä»¬äººå¯ä»¥å¾ˆæ˜æ˜¾çš„åŒºåˆ†èŠ±çº¹å’ŒçœŸæ­£çš„é›¨æ»´ï¼Œé‚£ä¹ˆä¸å°±è¯´æ˜è¿™ä¸¤è€…åœ¨è§†è§‰ä¸Šå°±æ˜¯æœ‰æœ¬è´¨åŒºåˆ«çš„ã€‚å…·ä½“è€Œè¨€ï¼š

**é›¨ä¸**ï¼šåœ¨æ•´ä¸ªå›¾åƒä¸­é‡å¤å‡ºç°ï¼Œæ–¹å‘åˆ†å¸ƒéšæœºä½†ç¬¦åˆç‰©ç†è§„å¾‹ï¼ˆé€è§†æ•ˆæœï¼‰ï¼ŒåŒæ—¶ç”±äºè¿åŠ¨æ¨¡ç³Šå’Œå…‰åå°„ï¼Œå…·æœ‰ç‰¹å®šçš„äº®åº¦æ¸å˜å’Œæ¨¡ç³Šè¾¹ç•Œ

**èŠ±çº¹**ï¼šé€šå¸¸å±€é™äºç‰¹å®šç‰©ä½“è¡¨é¢ï¼ˆå¦‚è¡£æœæ¡çº¹ã€å»ºç­‘çº¹ç†ï¼‰ï¼Œä¸”æœ‰æ¸…æ™°çš„è¾¹ç•Œå’Œä¸€è‡´çš„å¯¹æ¯”åº¦

#### 2.é›¨éå¸¸å¤§æ—¶ï¼Œå¯†é›†çš„é›¨ä¸å¯èƒ½ä¼šå®Œå…¨é®æŒ¡ä½èƒŒæ™¯çš„ä¸€äº›ç»†èŠ‚ï¼ˆæ¯”å¦‚å»ºç­‘çš„è½®å»“çº¿ï¼‰ã€‚åœ¨è¿™ç§å› å¹²æ‰°è€Œéš¾ä»¥åˆ†è¾¨çš„æƒ…å†µä¸‹ï¼Œ**æ¨¡å‹è¿˜æœ‰å¯èƒ½å¤åŸå‡ºåŸæ¥çš„ç‰©ä½“å—ï¼Ÿ**

æˆ‘è®¤ä¸ºæœ‰å¯èƒ½ï¼Œä½†å¦‚æœé®æŒ¡çš„è¿‡äºå‰å®³ï¼Œæœ‰å¯èƒ½ä¹Ÿæ— æ³•å®Œå…¨æ¢å¤ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æµ·é‡çš„æ•°æ®è®­ç»ƒæ¥è·å¾—å›¾ç‰‡çš„ä¸€äº›è§„å¾‹ï¼Œæ¯”å¦‚å»ºç­‘çš„è½®å»“ä¸ä¸Šä¸‹é—´çš„å…³ç³»ï¼Œå»ºç­‘ä¸Šæœ‰çª—æˆ·ç­‰ç­‰ï¼Œä½†å¦‚æœé®æŒ¡å…³äºä¸¥é‡æˆ–è€…è¯¥ç…§ç‰‡çš„æ¨¡å¼æˆ‘ä»¬æ²¡æœ‰è®­ç»ƒï¼Œä¹Ÿå¯èƒ½å¯¼è‡´ä¿¡æ¯æ— æ³•å®Œå…¨ä¿®å¤ã€‚

## Task2-æ€ä¹ˆä¼˜åŒ–ä½ çš„æ¨¡å‹ï¼Ÿ

### ç›®æ ‡å‡½æ•°ï¼š

**L1ã€L2 èŒƒæ•°çš„å®šä¹‰æ˜¯ä»€ä¹ˆï¼Ÿåœ¨å‡ ä½•æ„ä¹‰ä¸Šè¡¨ç¤ºä»€ä¹ˆæ„æ€ï¼Ÿ**

ä»€ä¹ˆæ˜¯èŒƒæ•°ï¼Ÿ

è¿™ä¸ªå…¶å®æ˜¯æ•°å­¦ä¸Šçš„æ¦‚å¿µï¼Œç®€å•æ¥è¯´ï¼Œå…¶å®šä¹‰çš„å‡½æ•°è¦æ»¡è¶³æ­£å®šæ€§ï¼Œç»å¯¹é½æ¬¡æ€§ï¼Œä¸‰è§’ä¸ç­‰å¼ã€‚

L1èŒƒæ•°ï¼š

L1èŒƒæ•°å°±æ˜¯å¯¹æ¯ä¸ªXiçš„ç»å¯¹å€¼æ±‚åˆï¼Œå…¶åœ¨å‡ ä½•æ„ä¹‰ä¸Šè¡¨ç¤ºçš„å°±æ˜¯æ›¼å“ˆé¡¿è·ç¦»

L2 èŒƒæ•°ï¼š

L2èŒƒæ•°å…¶å®å°±æ˜¯å¯¹Xiçš„å¹³æ–¹æ±‚åˆåå†å¼€æ–¹ï¼Œç®€å•æ¥è¯´ï¼Œå…¶å’Œå‘é‡çš„æ¨¡é•¿æ˜¯ç›¸ä¼¼çš„ï¼Œå…¶åœ¨å‡ ä½•ä¸Šè¡¨ç¤ºçš„å°±æ˜¯å‡ ä½•è·ç¦»

**è®¡ç®—è¿‡ç¨‹æ˜¯æ€æ ·çš„ï¼Ÿ**

æˆ‘ä»¬å¯ä»¥å¯¹çœŸå®çš„æ— é›¨å›¾åƒå’Œæˆ‘ä»¬predçš„æ— é›¨å›¾åƒçš„æ¯ä¸ªåƒç´ ç‚¹ä¸Šæ•°æ®ï¼ˆæˆ‘ä»¬åœ¨èŠ±å‰ä¸­å¾—åˆ°äº†è¡¨ç¤ºå›¾åƒçš„å¼ é‡æ ¼å¼â€”â€”PILæ ¼å¼ï¼‰ç›¸å‡ï¼Œé€šè¿‡L1æˆ–è€…L2æ¥å¾—åˆ°æŸå¤±ï¼ˆåŒæ—¶è¦å–å¹³å‡ï¼‰ï¼Œå…¶å®æˆ‘ä»¬ä¸€èˆ¬ä½¿ç”¨çš„MSEå°±æ˜¯åŸºäºL2çš„æŸå¤±

### è¯„ä¼°æŒ‡æ ‡

#### 1.**PSNRï¼ˆå³°å€¼ä¿¡å™ªæ¯”ï¼‰**

å³°å€¼ä¿¡å™ªæ¯”çš„å®šä¹‰å¦‚ä¸‹ï¼š

ä½œä¸ºå¯¹æ•°åˆ†å­çš„ï¼Œæ˜¯è¡¨ç¤ºå›¾åƒç‚¹é¢œè‰²çš„æœ€å¤§å€¼ï¼ˆå¦‚æœæ¯ä¸ªé‡‡æ ·ç‚¹ç”¨ 8 ä½è¡¨ç¤ºï¼Œå°±æ˜¯ 255ï¼‰çš„å¹³æ–¹ã€‚å¯¹äºåˆå­¦è€…è€Œè¨€ï¼Œå¯ä»¥æš‚æ—¶å°† 	`MAX_I` ç†è§£ä¸ºä¸€ä¸ª**å›ºå®šå€¼**

ä½œä¸ºå¯¹æ•°åˆ†æ¯çš„ï¼Œæ˜¯ä¸¤å¼ å›¾åƒåœ¨æ‰€æœ‰åƒç´ ä¸Šçš„**å‡æ–¹è¯¯å·® (MSE)** ã€‚MSE çš„è®¡ç®—æ–¹å¼æºäº L2 èŒƒæ•°ï¼Œè¿™ä½¿å¾— PSNR æŒ‡æ ‡å¯¹å¼‚å¸¸å€¼ï¼ˆå³å·®å¼‚	ç‰¹åˆ«å¤§çš„åƒç´ ç‚¹ï¼‰éå¸¸æ•æ„Ÿï¼ˆä¸ºäº†ç¬”è®°çš„å®Œæ•´ï¼Œç›´æ¥copyå­¦é•¿çš„æè¿°ï¼‰

#### 2.**SSIMï¼ˆç»“æ„ç›¸ä¼¼æ€§ï¼‰**

**æ¦‚è¿°ï¼š**

å…¶æ˜¯ä¸€ä¸ªè¡¡é‡å›¾ç‰‡çš„ç›¸ä¼¼æ€§çš„ä¸€ä¸ªç‰©ç†é‡ï¼Œä»–å°†å›¾ç‰‡ç›¸ä¼¼æ€§åˆ†è§£åˆ°ä¸‰ä¸ªé€šé“ä¸Šï¼šäº®åº¦ï¼Œå¯¹æ¯”åº¦å’Œç»“æ„ã€‚è®©æˆ‘ä»¬å…ˆç»™å‡ºSSIMçš„å…¬å¼ï¼š

![f0dfdefb-3703-443a-869c-e1f272a74539](./Img/f0dfdefb-3703-443a-869c-e1f272a74539.png)

åœ¨è¿™é‡Œï¼ŒÎ¼è¡¨ç¤ºå›¾åƒçš„å‡å€¼ï¼ŒÏƒè¡¨ç¤ºæ–¹å·®ï¼ŒÏƒâ‚“áµ§è¡¨ç¤ºåæ–¹å·®ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘æ²¡æœ‰ç ”ç©¶è¿™ä¸ªå‡½æ•°çš„å…·ä½“å®šä¹‰ï¼Œä½†æˆ‘ä»¬å¯ä»¥ç®€å•æ„Ÿå—ï¼Œå½“ä¸¤è€…çš„å·®åˆ«è¶Šå¤§ï¼ŒSSIMè¶Šå°ï¼Œè€Œè‹¥ä¸¤è€…å®Œå…¨ç›¸åŒï¼Œåˆ™SSIMä¸º1ã€‚

**SSIM çš„æ•°å€¼èŒƒå›´æ˜¯å¤šå°‘ï¼Ÿ**

SSIM çš„æ•°å€¼èŒƒå›´æ˜¯ [-1, 1]ã€‚ç®€å•æ¥è¯´ï¼Œè‹¥ä¸¤å¹…å›¾ç‰‡å®Œå…¨ç›¸åŒï¼Œåˆ™SSIM=1ï¼Œåä¹‹ï¼Œè‹¥å®Œå…¨ç›¸åï¼ˆæ¯ä¸ªåƒç´ ç‚¹ç‚¹æ•°å€¼ç›¸åŠ ä¸º255ï¼‰ï¼Œæ­¤æ—¶SSIM=-1ã€‚

**SSIM å¯¹å›¾ç‰‡çš„è€ƒè™‘ä¸»è¦ä»å“ªå‡ ä¸ªè§’åº¦ï¼Ÿ**

ä¸»è¦å°±æ˜¯ä»äº®åº¦ï¼Œå¯¹æ¯”åº¦å’Œç»“æ„ä¸‰ä¸ªæ–¹é¢æ¥è€ƒè™‘ã€‚

**ä¸åŒäº PSNRï¼ŒSSIM æ¯ä¸€æ¬¡çš„è¯„ä¼°å¯¹è±¡æ˜¯ä»€ä¹ˆï¼Ÿ**

**PSNR**çš„è¯„ä¼°å¯¹è±¡æ˜¯æ•´å¼ å›¾ç‰‡çš„æ‰€æœ‰åƒç´ ã€‚å®ƒè®¡ç®—çš„æ˜¯æ‰€æœ‰åƒç´ ä¸Šçš„å‡æ–¹è¯¯å·®ï¼Œç„¶åè½¬æ¢æˆä¸€ä¸ªåˆ†å€¼ã€‚å®ƒæ˜¯ä¸€ä¸ª**å…¨å±€çš„**è¯„ä¼°å€¼ã€‚

**SSIM** çš„è¯„ä¼°å¯¹è±¡æ˜¯å›¾ç‰‡ä¸­çš„ä¸€ä¸ªå±€éƒ¨å°çª—å£ã€‚SSIM ç®—æ³•ä¼šç”¨ä¸€ä¸ªæ»‘åŠ¨çª—å£åœ¨ä¸¤å¼ å›¾ç‰‡ä¸Šé€å—ç§»åŠ¨ã€‚åœ¨æ¯ä¸€ä¸ªçª—å£å†…ï¼Œåˆ†åˆ«è®¡ç®—äº®åº¦ã€å¯¹æ¯”åº¦å’Œç»“æ„çš„ç›¸ä¼¼åº¦ï¼Œå¾—åˆ°ä¸€ä¸ªå±€éƒ¨çš„ SSIM å€¼ã€‚æœ€åï¼Œå°†æ‰€æœ‰å±€éƒ¨çª—å£çš„ SSIM å€¼è¿›è¡Œå¹³å‡ï¼Œå¾—åˆ°ä¸€ä¸ªä»£è¡¨æ•´å¼ å›¾ç‰‡çš„æœ€ç»ˆ SSIM å€¼ã€‚æ•…å…¶å®SSIMçš„è¿‡ç¨‹æœ‰ç‚¹åƒæˆ‘ä»¬ä½¿ç”¨å·ç§¯å¹¶è¿›è¡Œæ± åŒ–ã€‚

## Task3-ä»»åŠ¡ä¸‰ï¼šæˆ‘æœ‰è¯´æ˜ä¹¦ï¼Œå¤ªå¥½å•¦

### ç¯å¢ƒæ­å»ºï¼šå°èœä¸€ç¢Ÿ

![e669f983-4774-4288-b22c-b1a9da66014f](./Img/e669f983-4774-4288-b22c-b1a9da66014f.png)

![5e453943-40dc-45c1-ba8c-cb7e21e09b71](./Img/5e453943-40dc-45c1-ba8c-cb7e21e09b71.png)

###  å®ç°ä¸€ä¸ªç®€å•çš„æ¨¡å‹

#### 1.ResNetçš„æ„å»º

```python
import torch
import torch.nn as nn
import torch.nn.functional as F


class ResidualBlock(nn.Module):
    def __init__(self, in_channels=64, out_channels=64, stride=1):
        super(ResidualBlock, self).__init__()

        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,
                               stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)

        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,
                               stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.shortcut = nn.Sequential()
    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += self.shortcut(x)
        out = F.relu(out)
        return out


class BaselineNet(nn.Module):
    def __init__(self, in_channels=3, out_channels=3, base_channels=64):
        super(BaselineNet, self).__init__()

        self.conv1 = nn.Conv2d(in_channels, base_channels, kernel_size=3,
                               stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(base_channels)

        self.layer1 = ResidualBlock(base_channels, base_channels, stride=1)
        self.layer2 = ResidualBlock(base_channels, base_channels, stride=1)
        self.layer3 = ResidualBlock(base_channels, base_channels, stride=1)
        self.layer4 = ResidualBlock(base_channels, base_channels, stride=1)

        self.conv_final = nn.Conv2d(base_channels, out_channels, kernel_size=3,
                                    stride=1, padding=1)

        self._initialize_weights()

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

    def forward(self, x):
        identity = x

        out = F.relu(self.bn1(self.conv1(x)))
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        out = self.conv_final(out)

        output = identity + out
        return output
```

#### 2.è§£å†³æ„Ÿå—é‡å—é™çš„é—®é¢˜

è®©æˆ‘ä»¬å…ˆæ¥ä»‹ç»å‡ ä¸ªæ¦‚å¿µã€‚

##### ç©ºæ´å·ç§¯ï¼š

å®ƒé€šè¿‡åœ¨å·ç§¯æ ¸å…ƒç´ ä¹‹é—´æ’å…¥ç©ºæ ¼ï¼ˆç©ºæ´ï¼‰æ¥**æ‰©å¤§æ„Ÿå—é‡**ï¼ŒåŒæ—¶**ä¸å¢åŠ å‚æ•°æ•°é‡**æˆ–**é™ä½åˆ†è¾¨ç‡**ã€‚ç®€å•æ¥è¯´ï¼Œå®ƒå°±æ˜¯å…ˆé€šè¿‡åŠ å…¥0çš„æ–¹å¼æ‰©å¤§æ•´ä¸ªå·ç§¯æ ¸ï¼Œä½†ç”±äº0çš„ä½ç½®ä¸æ”¹å˜æ•´ä¸ªç»“æ„ï¼Œæ‰€ä»¥å®é™…çš„å·ç§¯æ ¸çš„å¤§å°æ˜¯ä¸å˜çš„

##### é‡‘å­—å¡”æ± åŒ– ï¼š

ç›¸æ¯”ä¼ ç»Ÿçš„æ± åŒ–ï¼Œé‡‘å­—å¡”æ± åŒ–é€šè¿‡å¤šä¸ªå¹¶è¡Œæ± åŒ–åˆ†æ”¯ï¼Œç”±æ­¤å¯ä»¥æ•è·ä»ç²¾ç»†åˆ°ç²—ç³™çš„å¤šå°ºåº¦ä¿¡æ¯ï¼Œä»è€Œæ‰©å¤§äº†æ„Ÿå—é‡å¹¶ä¸”åœ¨ä¸€å®šç¨‹åº¦ä¸Šæœ‰åŠ©äºå‡å°è¿‡æ‹Ÿåˆã€‚

### è¿™ä¸ªä»£ç æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ

#### è¿è¡Œä»£ç æˆªå›¾ï¼š

![2a9594fd-db35-41d0-b099-78049300c729](./Img/2a9594fd-db35-41d0-b099-78049300c729.png)

ä½†æˆ‘ä»¬æ³¨æ„åˆ°ï¼Œæ­¤æ—¶çš„SSIMå¹¶ä¸é«˜ï¼Œåªæœ‰0.39å·¦å³ï¼Œä½†åŒæ—¶æˆ‘ä»¬æ³¨æ„åˆ°æ­¤æ—¶çš„losså·²ç»ç¨³å®šåœ¨0.15,ç”šè‡³å‡ºç°äº†ä¸€å®šçš„è¿‡æ‹Ÿåˆï¼Œè¿™ä¹Ÿä¸ºæˆ‘ä»¬åœ¨ä¸‹æ–‡ç•™ä¸‹äº†å¥‘æœºã€‚

#### å­¦åˆ°çš„æ–°ä¸œè¥¿ï¼š

Resnetçš„æ•´ä½“ç»“æ„æˆ‘åœ¨èŠ±å‰é‚£é“é¢˜ä¸­åŸºæœ¬å·²ç»é˜è¿°äº†ï¼Œä½†è¿™é“é¢˜ä¸­å­¦åˆ°çš„ä¸€ä¸ªæœ‰è¶£çš„ä¸œè¥¿åè€Œæ˜¯ä¸‹é¢çš„åˆå§‹åŒ–çš„æ–¹å¼ã€‚

```python
def _initialize_weights(self):
    for m in self.modules():
        if isinstance(m, nn.Conv2d):
            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
        elif isinstance(m, nn.BatchNorm2d):
            nn.init.constant_(m.weight, 1)
            nn.init.constant_(m.bias, 0)
```

ä»¥å‰ï¼Œæˆ‘ä»¬åˆå§‹åŒ–éƒ½æ˜¯æ±‚åˆä¸º0å’Œæ–¹å·®ä¸º1æ¥æ¥åˆå§‹åŒ–wï¼Œå¹¶ç›´æ¥å°†bèµ‹å€¼ä¸º0ï¼Œè¿™å½“ç„¶æ˜¯å¯¹çš„ã€‚ä½†åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ä½¿ç”¨ **Kaimingæ­£æ€åˆ†å¸ƒ**æ¥åˆå§‹åŒ–æƒé‡ã€‚è¿™æ˜¯ä¸€ç§å¯¹äºCNNæ›´å¥½çš„åˆå§‹åŒ–æ–¹å¼ã€‚å…·ä½“è€Œè¨€ï¼Œå…¶æ­£æ€åˆ†å¸ƒå¦‚ä¸‹

![0bace24b-3c60-4267-941f-3942f4ab2998](./Img/0bace24b-3c60-4267-941f-3942f4ab2998.png)

ç›¸æ¯”äºæˆ‘ä»¬ä»¥å‰ä½¿ç”¨çš„çŠ¶æ€åˆ†å¸ƒï¼Œå…¶æœ€ä¸»è¦çš„åŒºåˆ«å°±æ˜¯å®ƒå°†æ–¹å·®ä»ä¸å˜çš„1æ”¹å˜ä¸ºä¸€ä¸ªä¸å²‘å±‚æ•°æœ‰å…³ï¼Œè¿™æ ·ä½¿å¾—ç½‘ç»œç»“æ„ï¼ˆfan_inæˆ–fan_outï¼‰è‡ªåŠ¨è°ƒæ•´æ–¹å·®ï¼Œä½¿å¾—æ¯ä¸€å±‚æ¿€æ´»å€¼çš„æ–¹å·®å¤§è‡´ä¸º1ï¼Œä»è€Œä¿æŒä¿¡å·åœ¨æ·±å±‚ç½‘ç»œä¸­çš„ç¨³å®šæµåŠ¨ã€‚åŒæ—¶ç³»æ•°2æ˜¯å› ä¸ºReLUä¼šå°†ä¸€åŠçš„è¾“å…¥ç½®é›¶ï¼Œæ‰€ä»¥æ–¹å·®ä¼šå‡åŠï¼Œè€Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¹˜2æ¥è¡¥å¿è¿™ä¸€æŸå¤±ã€‚

#### é™„åŠ ï¼š

å¯¹äºæ‰‹åŠ¨å®ç°ï¼Œæˆ‘ä»¬é¦–å…ˆè¦äº†è§£PSNRçš„å…¬å¼ï¼Œè¿™é‡Œæˆ‘ç›´æ¥è¯¢é—®deepseekï¼Œå¾—åˆ°äº†å¦‚ä¸‹çš„ç»“æœã€‚

![453d2c07-6407-4d6b-a209-e84a2ff2fe74](./Img/453d2c07-6407-4d6b-a209-e84a2ff2fe74.png)

æ•…æˆ‘ä»¬è¦éå†æ•´ä¸ªå›¾ç‰‡æ¥è®¡ç®—MSEï¼ŒåŒæ—¶åœ¨éå†çš„åŒæ—¶è¦å¯»æ‰¾MAXï¼Œæœ€ç»ˆç”±ç¬¬ä¸€ä¸ªå…¬å¼å°±å¯ä»¥è®¡ç®—PSNRã€‚åŒæ—¶ï¼Œæˆ‘ä»¬ä¸»è¦åˆ°ï¼Œå¦‚æœæˆ‘ä»¬å¯¹å›¾ç‰‡è¿›è¡Œäº†å½’ä¸€åŒ–ï¼Œé‚£ä¹ˆæ­¤æ—¶maxå°±åº”ä¸º1ã€‚

```python
def my_psnr(img1, img2):
    mse = np.mean((img1 - img2) ** 2)
    if img1.dtype == np.uint8:
        max = 255.0
    elif img1.max() <= 1.0 and img2.max() <= 1.0:
        max = 1.0
    else:
        max = max(np.max(img1), np.max(img2))
    psnr = 20 * math.log10(max / math.sqrt(mse))
    return psnr
```

# Part2 ä¼˜åŒ–æˆ‘ä»¬çš„ç®—æ³•

## Part2.1-é¦–å…ˆæˆä¸ºæ­ç§¯æœ¨é«˜æ‰‹

### Task1-æäº†åŠå¤©åŸæ¥è¦è‡ªå·±å†™

å®Œæ•´ç‰ˆè§pythonæ–‡ä»¶ï¼Œä¸»è¦ä¿®æ”¹å¦‚ä¸‹ï¼š

#### ä¸€ã€

```python
parser.add_argument("--model", type=str, default="baseline", choices=["baseline", "unet","DerainNet","Mymodel"], help="Model to use")
```

#### äºŒã€

```python
import torch
import torch.nn.functional as F
from torch import nn


class DerainNet(nn.Module):
    def __init__(self):
        super(DerainNet, self).__init__()
        pass
    def forward(self, x):
        pass
```

```python
from models.baseline_net import BaselineNet
from models.unet import UNet
from models.Mymodel import Mymodel
from models.DerainNet import DerainNet
from losses.perceptual_loss import PerceptualLoss
```

#### ä¸‰ã€

```python
def main():
    args = get_args()
    device = "mps" if torch.mps.is_available() else "cpu"
    print(f"Using device: {device}")

    if args.model == "baseline":
        model = BaselineNet().to(device)
    elif args.model == "unet":
        model = UNet().to(device)
    elif args.model == "DerainNet":
        model = DerainNet().to(device)
    elif args.model == "Mymodel":
        model = Mymodel().to(device)
```

### Task2-è¯•è¯•çœ‹å‰äººçš„æ°ä½œ

#### 1.ä»£ç ï¼š

```python
import torch
from torch import nn


class ResidualBlock(nn.Module):
    def __init__(self, channels):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)

    def forward(self, x):
        residual = x
        out = self.relu(self.conv1(x))
        out = self.conv2(out)
        out += residual
        return out


class DerainNet(nn.Module):
    def __init__(self, in_channels=3, base_channels=64, num_blocks=8):
        super(DerainNet, self).__init__()
        self.initial_conv = nn.Conv2d(in_channels, base_channels, kernel_size=3, padding=1)

        self.branch_full = self.Blocks(base_channels, num_blocks)
        self.branch_half = self.Blocks(base_channels, num_blocks)
        self.branch_quarter = self.Blocks(base_channels, num_blocks)

        self.pool_half = nn.MaxPool2d(kernel_size=2, stride=2)
        self.pool_quarter = nn.MaxPool2d(kernel_size=4, stride=4)

        self.upsample_half = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)
        self.upsample_quarter = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=False)

        self.trans= nn.Sequential(
            nn.Conv2d(base_channels * 3, base_channels, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(base_channels, in_channels, kernel_size=3, padding=1)
        )

    def Blocks(self, channels, num_blocks):   #å°†å‰é¢æˆ‘ä»¬å†™çš„8å±‚æ®‹å·®å—å°è£…åœ¨ä¸€ä¸ªå‡½æ•°ä¸­
        layers = []
        for _ in range(num_blocks):
            layers.append(ResidualBlock(channels))
        return nn.Sequential(*layers)

    def forward(self, x):
        x_initial = self.initial_conv(x)

        branch1_out = self.branch_full(x_initial) + x_initial

        x_half = self.pool_half(x_initial)
        branch2_out = self.branch_half(x_half) + x_half
        branch2_out = self.upsample_half(branch2_out)

        x_quarter = self.pool_quarter(x_initial)
        branch3_out = self.branch_quarter(x_quarter) + x_quarter
        branch3_out = self.upsample_quarter(branch3_out)

        concatenated = torch.cat([branch1_out, branch2_out, branch3_out], dim=1)
        rain_layer = self.trans(concatenated)
        deraining = x - rain_layer
        return deraining
```

#### 2.æµ‹è¯•æ¨¡å‹æ€§èƒ½ï¼š

![db2d0dd4-18dd-4ddf-8de4-809b9f40e5fe](./Img/db2d0dd4-18dd-4ddf-8de4-809b9f40e5fe.png)

![3acd3e54-89df-45bf-ab39-457e0fc8e838](./Img/3acd3e54-89df-45bf-ab39-457e0fc8e838.png)

#### 3.æ€è€ƒï¼š

##### 1.

ä¸‹é‡‡æ ·åœ¨ä¸Šé¢çš„æ¨¡å‹ä¸­å°±æ˜¯æ± åŒ–ï¼Œæœ¬è´¨å°±æ˜¯å‡å°‘å›¾åƒé¢ç§¯æ¥è·å¾—æ›´å¤§çš„æ„Ÿå—é‡ï¼Œè€Œä¸Šé‡‡æ ·å°±æ˜¯Upsimpleï¼ˆå…³äºå…¶çš„ç»†èŠ‚æˆ‘å†™åœ¨äº†ä¸‹é¢ï¼‰ï¼Œå…¶æœ¬è´¨å°±æ˜¯å¢åŠ å›¾åƒæˆ–ç‰¹å¾å›¾çš„ç©ºé—´å°ºå¯¸ï¼Œæ¥è·å¾—æ›´å¤šçš„ç»†èŠ‚ã€‚

é¦–å…ˆä¸‹é‡‡æ ·çš„åŸå› åº”è¯¥å°±æ˜¯ä¸ºäº†è§£å†³æ„Ÿå—é‡çš„é—®é¢˜ï¼Œä¸‹é‡‡æ ·å¯ä»¥è®©å›¾ç‰‡è·å¾—æ›´å¤§çš„æ„Ÿå—é‡çš„åŒæ—¶ä¹Ÿå°±ä¸€å®šç¨‹åº¦ä¸Šå‡å°äº†è®¡ç®—é‡ï¼Œé¿å…äº†æ¢¯åº¦çˆ†ç‚¸æˆ–è€…æ˜¯æ¢¯åº¦æ¶ˆå¤±çš„å¯èƒ½ã€‚è€Œä¸Šé‡‡æ ·çš„åŸå› æˆ‘è®¤ä¸ºæ˜¯ä¸ºäº†ä¿æŒå›¾ç‰‡å¤§å°çš„ä¸€è‡´æ€§ï¼Œæ¯•ç«Ÿå»é›¨ä»»åŠ¡çš„æœ¬è´¨å°±æ˜¯è¾“å‡ºä¸€ä¸ªä¸åŸå›¾ç‰‡å¤§å°ç›¸åŒçš„æ–°å›¾ç‰‡ã€‚åŒæ—¶ä¹Ÿä½¿å¾—ä¸‰è€…çš„å›¾åƒå¯ä»¥æ‹¼æ¥ã€‚è¿™æ ·åˆ†ä¸ºä¸‰ä¸ªå°ºåº¦é‡‡æ ·ä¹Ÿä½¿å¾—æ¨¡å‹å¯ä»¥å¯¹ä¸åŒå¤§å°çš„é›¨åˆ†å¼€å¤„ç†ã€‚

Concatæœ¬è´¨å°±æ˜¯åœ¨ç‰¹å®šçš„ç»´åº¦ä¸Šç»„åˆå¼ é‡çš„è¿‡ç¨‹ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œå…¶å°±æ˜¯æ²¿ç€Cè¿™ä¸ªç»´åº¦ç»„åˆå¼ é‡ï¼Œæœ€åå°†å…¶å˜ä¸º3C

##### 2.

**å…³äºUpsimpleï¼š**

è¿™ä¸ªå‡½æ•°ï¼ˆæ–¹æ³•ï¼‰ç¡®å®æˆ‘æ˜¯ç¬¬ä¸€æ¬¡å¬è¯´ï¼Œç®€å•æ¥è¯´å®ƒæ˜¯æ˜¯ PyTorch ä¸­ç”¨äºä¸Šé‡‡æ ·ï¼ˆæ”¾å¤§ï¼‰ç‰¹å¾å›¾çš„æ¨¡å—ï¼Œå¯ä»¥å°†å°å°ºå¯¸çš„ç‰¹å¾å›¾æ”¾å¤§åˆ°æ›´å¤§çš„å°ºå¯¸ã€‚å…¶å®åœ¨æˆ‘çœ‹æ¥Upsimpleä¸maxpoolå°±æ˜¯ä¸€å¯¹ç›¸å¯¹è€Œè¨€çš„æ–¹æ³•ï¼Œåè€…å°†å›¾åƒå‹ç¼©ä»è€Œå¯ä»¥è·å¾—æ›´å¤§çš„æ„Ÿå—é‡ï¼Œåè€…å°†å›¾ç‰‡æ¢å¤åˆ°åŸæœ‰çš„å¤§å°æ¥æ¢å¤å›¾ç‰‡çš„æ•´ä½“å½¢çŠ¶ã€‚

##### ä¸€äº›å°çš„æ€è€ƒï¼ˆä»¥ä¸‹è§‚ç‚¹çº¯å±ä¸ªäººçŒœæµ‹ğŸ˜Šï¼‰ï¼š

å…¶å®æˆ‘åœ¨ç ”ç©¶è¿™ä¸ªæ–¹æ³•çš„æ—¶å€™ï¼Œæˆ‘æƒ³åˆ°çš„æ˜¯èŠ±å‰é‚£é“é¢˜ã€‚åœ¨é‚£é“é¢˜ç›®ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨è£åˆ‡çš„æ•°æ®å¢å¼ºæ–¹å¼å¾—åˆ°äº†3ç»„å›¾ç‰‡ï¼Œè®©åæˆ‘æŠŠä¸‰ç»„å›¾ç‰‡ç”¨torch.catçš„æ–¹å¼æ‰©å¤§äº†3å€ï¼Œç„¶åä»£å…¥è®­ç»ƒï¼Œä½†åé¢æˆ‘ä»¬ä¹Ÿæ³¨æ„è¿™æ ·åšä¼šå¸¦æ¥ä¸€å®šç¨‹åº¦çš„è¿‡æ‹Ÿåˆã€‚è€Œæˆ‘ä»¬è£åˆ‡çš„ä¸»è¦ç›®çš„ä¸ä¹Ÿæ˜¯ä¸ºäº†åå»ä¸åŒçš„å¤§å°ï¼ˆæ„Ÿå—é‡ï¼‰ï¼Œé‚£æˆ‘ä»¬ç”¨è¿™ä¸ªæ–¹æ³•ä¸æ˜¯ä¹Ÿå¯ä»¥ä½¿å¾—èŠ±å‰çš„è®­ç»ƒæ•ˆæœæ›´å¥½ã€‚

## Part2.2

### Task1-åŸºäºåƒç´ åˆ°åº•æœ‰ä»€ä¹ˆä¸å¥½ï¼Ÿ

#### ä¸€ã€

æˆ‘ä»¬éƒ½çŸ¥é“ï¼Œä¸€ä¸ªå·ç§¯ç½‘ç»œæ˜¯æœ‰è‡ªå·±çš„æƒ³æ³•çš„ï¼Œæ¯”å¦‚ä»¥å‰æ‰€è¯´çš„è®­ç»ƒä¸€ä¸ªè¯†åˆ«è½¦è¾†çš„æ¨¡å‹ï¼Œé‚£ä¹ˆè¶Šé è¿‘è¾“å…¥å±‚ï¼Œå·ç§¯çš„è¯†åˆ«è¶Šå…³æ³¨ç»†èŠ‚ï¼Œè€Œè¶Šé è¿‘è¾“å‡ºå±‚ï¼Œå·ç§¯è¶Šå…³æ³¨æ•´ä½“ã€‚è€Œæˆ‘äº†è§£åˆ°ï¼Œé¢„è®­ç»ƒæ•°æ®ä¸»è¦æ¥è‡ªäºäººç±»æ ‡æ³¨ï¼Œéšå«äº†äººç±»æ„ŸçŸ¥åå¥½ï¼Œæ•…å½“æˆ‘ä»¬ç”¨æ­¤æ¨¡å‹é¢„è®­ç»ƒæ—¶ï¼Œæ¨¡å‹å¾—åˆ°çš„ä¿¡æ¯å½“ç„¶ä¹Ÿæ›´å…³æ³¨æ¨¡å‹çš„æ•´ä½“ï¼Œå¯¹è¿™æ ·çš„è¾“å‡ºå†æ±‚æŸå¤±ï¼ŒæŸå¤±å½“ç„¶ä¹Ÿå°±æ›´èƒ½ä½“ç°äººç±»æ‰€å…³æ³¨çš„éƒ¨åˆ†ã€‚

#### äºŒã€

å…¶å®æˆ‘è®¤ä¸ºçš„æ¨¡å‹çš„ä½œç”¨å·²ç»åœ¨ä¸€å¤„ç»™å‡ºäº†å›ç­”ï¼Œç°åœ¨è®©æˆ‘ä»¬æ¥å¯è§†åŒ–ä¸€ä¸‹è¿™ä¸ªè®­ç»ƒç»“æœã€‚

```python
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import matplotlib.pyplot as plt


class VGG19(nn.Module):
    def __init__(self):
        super(VGG19, self).__init__()
        vgg = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1)
        self.features = nn.Sequential(*list(vgg.features.children())[:35])
        for param in self.parameters():
            param.requires_grad = False

    def forward(self, x):
        return self.features(x)


def model_features(image_path):
    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    image = Image.open(image_path).convert('RGB')
    input_tensor = transform(image).unsqueeze(0).to(device)
    model = VGG19().to(device)
    model.eval()

    with torch.no_grad():
        features = model(input_tensor)

    features_np = features.squeeze(0).cpu().numpy()
    visualize(image, features_np)
    return features_np


def visualize(original_image, features):
    fig, axes = plt.subplots(1, 2, figsize=(12, 8))
    axes[0].imshow(original_image)
    axes[0].set_title('Original')
    axes[0].axis('off')
    feature_map = features[2]
    feature_map = (feature_map - feature_map.min()) / (feature_map.max() - feature_map.min())#å½’ä¸€åŒ–
    axes[1].imshow(feature_map, cmap='viridis')  #è¿™æ˜¯ä¸€ç§ç»å…¸çš„è‰²å½©æ˜ å°„
    axes[1].set_title('Feature')
    axes[1].axis('off')
    plt.tight_layout()
    plt.show()


if __name__ == "__main__":
    image_path = ("./data/Rain200L/train/target/1.png")
    features = model_features(image_path)
    print(features.shape)
```

è¿™æ˜¯å¯è§†åŒ–çš„ç¨‹åºï¼Œå…¶è¾“å‡ºçš„featureså¦‚ä¸‹

![f2e16b85-718d-45c7-92e1-b8ddfa6ec246](./Img/f2e16b85-718d-45c7-92e1-b8ddfa6ec246.png)

è¿™é‡Œæˆ‘ä»¬æ³¨æ„åˆ°ï¼Œæ­¤æ—¶çš„è¾“å‡ºæ˜¯ä¸€ä¸ª512ç»´çš„å›¾ç‰‡ï¼Œæˆ‘ä»¬è¾“å‡ºå…¶ä¸­çš„å‡ ä¸ªæ¥çœ‹ä¸€ä¸‹

![4f9ad899-e181-4662-825d-21e2d4124dcd](./Img/4f9ad899-e181-4662-825d-21e2d4124dcd.png)

![59f1162c-fc50-40eb-857b-dc24a20956ec](./Img/59f1162c-fc50-40eb-857b-dc24a20956ec.png)

![6f9300a1-43bc-49c9-a882-4b2884c6fcfd](./Img/6f9300a1-43bc-49c9-a882-4b2884c6fcfd.png)

![650988ca-4677-4584-a60e-3152f676e86d](./Img/a2ef778b-e6b5-410a-a50b-33a5db021903.png)

![04002abf-49f8-428a-89c1-0cb41ceb08f4](./Img/04002abf-49f8-428a-89c1-0cb41ceb08f4.png)

æˆ‘ä»¬å¯ä»¥çœ‹å‡ºï¼Œå¯¹äºä¸€å¼ å›¾ç‰‡ä¸­ï¼Œæˆ‘ä»¬è¶Šæ³¨æ„åˆ°çš„ç‚¹ï¼Œç›¸åº”çš„Featureä¸­çš„ç‚¹ä¹Ÿå°±è¶Šæ·±ï¼Œä¹Ÿå°±æ˜¯è¯´å¯¹åº”çš„å¼ é‡ä¸­çš„å æ¯”å°±è¶Šå¤§ï¼Œä¹Ÿå°±æ˜¯è¯´å­å•Šlossä¸­è¶Šé‡è¦ï¼Œå…¶å®å°±æ˜¯æˆ‘ä»¬åœ¨å‰é¢æåˆ°çš„é¢„è®­ç»ƒçš„ç›®çš„ã€‚

#### ä¸‰ã€

è®­ç»ƒç»“æœï¼š

![4a498f32-b58b-4be7-b1ec-1246883b88ff](./Img/4a498f32-b58b-4be7-b1ec-1246883b88ff.png)

![0d296891-8445-4e0f-90c3-ad8ef0ae3e7d](./Img/0d296891-8445-4e0f-90c3-ad8ef0ae3e7d.png)

### Task2-ä½ çŸ¥é“ä»€ä¹ˆæ˜¯å‘é‡å—ï¼Ÿ

#### ä¸€ã€

åœ¨é«˜ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰çš„å°±æ˜¯æœ‰æ–¹å‘å’Œå¤§å°çš„é‡ï¼Œè¿™åœ¨äºŒç»´å’Œä¸‰ç»´ä¸­æ˜¯å¾ˆå¥½ç†è§£çš„ï¼Œæˆ‘ä»¬åœ¨é«˜ä¸­ä¹Ÿå­¦ä¹ è¿‡ï¼Œä½†å¯¹äºå¤šç»´å‘é‡ï¼Œæˆ‘ä»¬å°±è¦ç”¨ç»´åº¦æ¥è¡¡é‡ã€‚å¦‚å››ç»´å‘é‡ï¼ˆaï¼Œbï¼Œcï¼Œdï¼‰ï¼Œè¿™äº›å¤šç»´å‘é‡åœ¨mlä¸­å…¶å®å¾ˆå¸¸è§ã€‚æœ‰ä¸€ç§è¯´æ³•å°±æ˜¯ï¼Œåœ¨pythonä¸­ï¼Œå¼ é‡å’Œå‘é‡çš„åŒºåˆ«å…¶å®æ˜¯ä¸å¤§çš„ã€‚

#### äºŒã€

å†…ç§¯æœ‰ä¸¤ç§å®šä¹‰ã€‚æœ€ç®€å•çš„å°±æ˜¯ä»£æ•°å®šä¹‰ã€‚å³

![a9d80157-f67c-4234-bcb3-eee870ff09f9](./Img/a9d80157-f67c-4234-bcb3-eee870ff09f9.png)

åœ¨é«˜ä¸­ï¼Œæˆ‘ä»¬è¿˜çŸ¥é“å†…ç§¯è¿˜æœ‰ä¸€ç§å‡ ä½•å«ä¹‰ï¼Œå³è¡¨ç¤ºä¸€ä¸ªå‘é‡åœ¨å¦ä¸€ä¸ªå‘é‡çš„æŠ•å½±ã€‚

#### ä¸‰ã€

ä½™å¼¦ç›¸ä¼¼åº¦è¿™ä¸ªæ¦‚å¿µå…¶å®æˆ‘ä»¬åœ¨é£æ ¼è¿ç§»ä¸­å·²ç»é˜è¿°è¿‡äº†ï¼Œè¿™é‡Œæˆ‘ä»¬ç›´æ¥æŠŠå½“æ—¶çš„é˜è¿°copyä¸€ä¸‹å§

**é£æ ¼æŸå¤±é€šè¿‡æ¯”è¾ƒç‰¹å¾ç»Ÿè®¡é‡ï¼ˆGramçŸ©é˜µï¼‰æ¥è¡¡é‡é£æ ¼ç›¸ä¼¼æ€§ã€‚é‚£ä»€ä¹ˆæ˜¯gramçŸ©é˜µå‘¢ï¼Œè€Œä¸ºä»€ä¹ˆå†…ç§¯èƒ½è¡¨ç¤ºä¸¤ä¸ªé€šé“é—´çš„ç›¸ä¼¼åº¦ï¼Ÿè¿™æˆ‘ä»¬å°±å…ˆæ¥å›ç­”ä¸‰ä¸ªé—®é¢˜ã€‚å®ç°gramçŸ©é˜µé€šè¿‡XÂ·X.Tæ¥åæ˜ xiå’Œxjçš„å†…ç§¯ï¼Œè¿™æ˜¯ç®€å•çš„çŸ©é˜µä¹˜æ³•ã€‚è€Œæˆ‘ä»¬æœ‰çŸ¥é“ï¼Œå†…ç§¯å¯ä»¥è¡¨ç¤ºä¸ºä¸¤ä¸ªå‘é‡çš„æ¨¡é•¿ä¹˜ä»¥å¤¹è§’ï¼Œåœ¨æˆ‘ä»¬è®¤ä¸ºåœ¨ä¸åŒçš„é€šé“ä¸Šä¸¤è€…çš„æ¨¡é•¿åŒºåˆ«ä¸å¤§ï¼Œåˆ™gramä¸è§’åº¦ç›¸å…³ï¼Œè€Œè§’åº¦è¶Šå°ï¼Œä¸¤è€…çš„ç›¸å…³æ€§ä¹Ÿå°±è¶Šå¤§ï¼Œæ•…gramå¯ä»¥åæ˜ ä¸åŒçš„é€šé“ï¼ˆRGBï¼‰ä¹‹é—´çš„å·®å¼‚åŒ–çš„å¤§å°ï¼Œè¿›è€Œå†³å®šè‰²å½©é£æ ¼çš„å€¾å‘ï¼Œè€Œé¢„æµ‹å€¼å’Œstyleä¸¤è€…çš„å‡æ–¹è¯¯å·®å°±å¯ä»¥åæ˜ é£æ ¼å·®å¼‚äº†ã€‚**

è¿™é‡Œæˆ‘ä»¬åœ¨æ€»ç»“ä¸€ä¸‹ï¼Œå…¶å®å°±æ˜¯ç”¨å†…ç§¯é™¤ä»¥å‘é‡çš„æ¨¡é•¿æ¥åæ˜ ä¸¤è€…çš„ç›¸ä¼¼åº¦ã€‚

### Task3-æ”¹é€ æ„ŸçŸ¥æŸå¤±å‡½æ•°ï¼Œä½¿ç”¨ç‰¹å¾åšå¯¹æ¯”

å…¶å®1ï¼Œ2æ˜¯ç›¸å…³çš„ï¼Œä½¿ç”¨æˆ‘ç›´æ¥å±•ç¤ºä¿®æ”¹å¥½çš„ä»£ç ã€‚

```python
import torch
import torch.nn as nn
from torchvision.models import vgg19, VGG19_Weights
import torch.nn.functional as F

class EasyContrastiveLoss(nn.Module):
    def __init__(self):
        super(EasyContrastiveLoss, self).__init__()
        vgg = vgg19(weights=VGG19_Weights.IMAGENET1K_V1)
        self.features = nn.Sequential(*list(vgg.features.children())[:35])
        for param in self.parameters():
            param.requires_grad = False
        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))

    def trans_vector(self, x):
        features = self.features(x)
        features = self.adaptive_pool(features).squeeze(-1).squeeze(-1)
        return features

    def forward(self,input,generated, ground_truth):
        input_vector= self.trans_vector(input)
        generated_vector = self.trans_vector(generated)
        ground_truth_vector = self.trans_vector(ground_truth)
        sim_pos = F.cosine_similarity(generated_vector, ground_truth_vector, dim=1)
        sim_neg = F.cosine_similarity(generated_vector, input_vector, dim=1)
        loss = (1 - sim_pos).mean() + sim_neg.mean()
        return loss
```

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from tqdm import tqdm
import argparse
import os
import lpips

from dataset import DerainDataset
from utils import calculate_metrics, save_checkpoint, load_checkpoint, save_some_examples
from models.baseline_net import BaselineNet
from models.unet import UNet
from models.Mymodel import Mymodel
from models.DerainNet import DerainNet
from losses.perceptual_loss import PerceptualLoss
from losses.easy_contrastive_loss import EasyContrastiveLoss


def get_args():
    parser = argparse.ArgumentParser(description="Deraining Model Training")
    parser.add_argument("--data_dir", type=str, required=True, help="Path to the dataset")
    parser.add_argument("--model", type=str, default="baseline", choices=["baseline", "unet","DerainNet","Mymodel"], help="Model to use")
    parser.add_argument("--mode", type=str, default="train", choices=["train", "test"], help="Train or test mode")
    parser.add_argument("--checkpoint", type=str, default=None, help="Path to checkpoint for testing")

    parser.add_argument("--epochs", type=int, default=20, help="Number of training epochs")
    parser.add_argument("--batch_size", type=int, default=8, help="Batch size")
    parser.add_argument("--lr", type=float, default=1e-4, help="Learning rate")

    parser.add_argument("--use_perceptual_loss", action="store_true", help="Use perceptual loss")
    parser.add_argument("--use_easy_contrastive_loss", action="store_true", help="Use easy_contrastive loss")
    parser.add_argument("--lambda_pixel", type=float, default=1.0, help="Weight for pixel loss")
    parser.add_argument("--lambda_perceptual", type=float, default=0.1, help="Weight for perceptual loss")
    parser.add_argument("--lambda_contrastive", type=float, default=0.1, help="Weight for contrastive loss")

    return parser.parse_args()


def train_one_epoch(loader, model, optimizer, pixel_loss_fn, perceptual_loss_fn,contrastive_loss_fn, args, device):
    loop = tqdm(loader, leave=True)
    model.train()

    for _, (rainy, clean, _) in enumerate(loop):
        rainy, clean = rainy.to(device), clean.to(device)
        derained = model(rainy)
        pixel_loss = args.lambda_pixel * pixel_loss_fn(derained, clean)
        total_loss = pixel_loss
        if args.use_perceptual_loss:
            p_loss = args.lambda_perceptual * perceptual_loss_fn(derained, clean)
            total_loss += p_loss
            loop.set_postfix(pixel_loss=pixel_loss.item(), perceptual_loss=p_loss.item())
        if args.use_easy_contrastive_loss:
            c_loss = args.lambda_contrastive * contrastive_loss_fn(rainy, derained, clean)
            total_loss += c_loss
            loop.set_postfix(contrastive_loss=c_loss.item())
        else:
            loop.set_postfix(pixel_loss=pixel_loss.item())
        optimizer.zero_grad()
        total_loss.backward()
        optimizer.step()


def evaluate(loader, model, device, lpips_fn):
    model.eval()
    total_psnr, total_ssim, total_lpips = 0, 0, 0

    with torch.no_grad():
        for rainy, clean, _ in loader:
            rainy, clean = rainy.to(device), clean.to(device)
            derained = model(rainy)

            psnr, ssim, lpips_score = calculate_metrics(derained, clean, lpips_fn)
            total_psnr += psnr
            total_ssim += ssim
            total_lpips += lpips_score

    avg_psnr = total_psnr / len(loader)
    avg_ssim = total_ssim / len(loader)
    avg_lpips = total_lpips / len(loader)

    print(f"EVAL => Avg PSNR: {avg_psnr:.4f} | Avg SSIM: {avg_ssim:.4f} | Avg LPIPS: {avg_lpips:.4f}")
    return avg_psnr


def main():
    args = get_args()
    device = "mps" if torch.mps.is_available() else "cpu"
    print(f"Using device: {device}")

    if args.model == "baseline":
        model = BaselineNet().to(device)
    elif args.model == "unet":
        model = UNet().to(device)
    elif args.model == "DerainNet":
        model = DerainNet().to(device)
    elif args.model == "Mymodel":
        model = Mymodel().to(device)


    lpips_fn = lpips.LPIPS(net='alex').to(device)

    pixel_loss_fn = nn.L1Loss()
    perceptual_loss_fn = PerceptualLoss().to(device) if args.use_perceptual_loss else None
    contrastive_loss_fn = EasyContrastiveLoss().to(device) if args.use_easy_contrastive_loss else None
    optimizer = optim.Adam(model.parameters(), lr=args.lr)

    if args.mode == "train":
        train_dataset = DerainDataset(root_dir=args.data_dir, is_train=True)
        train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4)
        test_dataset = DerainDataset(root_dir=args.data_dir, is_train=False)
        test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)

        best_psnr = 0.0
        for epoch in range(args.epochs):
            print(f"\n--- Epoch {epoch + 1}/{args.epochs} ---")
            train_one_epoch(train_loader, model, optimizer, pixel_loss_fn, perceptual_loss_fn,contrastive_loss_fn,args, device)

            current_psnr = evaluate(test_loader, model, device, lpips_fn)

            if current_psnr > best_psnr:
                best_psnr = current_psnr
                checkpoint_data = {"state_dict": model.state_dict(), "optimizer": optimizer.state_dict()}
                model_name_parts = [args.model]
                if args.use_perceptual_loss:
                    model_name_parts.append("perceptual")
                if args.use_easy_contrastive_loss:
                    model_name_parts.append("contrastive")
                model_name = "_".join(model_name_parts) + ".pth.tar"

                save_checkpoint(checkpoint_data, filename=f"best_{model_name}")
                print(f"Saved best model with PSNR: {best_psnr:.4f}")

            save_some_examples(model, test_loader, epoch, folder="evaluation_images", device=device)

    elif args.mode == "test":
        if not args.checkpoint: raise ValueError("Must provide a checkpoint for test mode.")
        load_checkpoint(torch.load(args.checkpoint, map_location=device), model, optimizer)
        test_dataset = DerainDataset(root_dir=args.data_dir, is_train=False)
        test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)

        evaluate(test_loader, model, device, lpips_fn)


if __name__ == "__main__":
    if not os.path.exists("checkpoints"): os.makedirs("checkpoints")
    main()
```

![2bfa0f96-6879-4d17-acfe-299c7e75c390](./Img/2bfa0f96-6879-4d17-acfe-299c7e75c390.png)

![c2ffb696-e7b8-4915-84ba-2a93ded8ca73](./Img/c2ffb696-e7b8-4915-84ba-2a93ded8ca73.png)

 ä¸è¿‡å¥½åƒç¡®å®SSIMæ¯”ä¸Šé¢ä¸€ä¸ªæ¨¡å‹ä½äº†
